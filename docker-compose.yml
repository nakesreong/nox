version: '3.8'

services:
#  vllm:
#    image: vllm/vllm-openai:latest
#    deploy:
#      resources:
#        reservations:
#          devices:
#            - driver: nvidia
#              count: all
#              capabilities: [gpu]
#    environment:
#      - HUGGING_FACE_HUB_TOKEN=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
#    volumes:
#      - ./models:/root/.cache/huggingface
#    ports:
#      # Открываем порт 8000 на всех сетевых интерфейсах "Предатора"
#      - "8000:8000"
#    command:
#      - "--model"
#      - "google/gemma-3n-E2B-it"
#      - "--trust-remote-code"
#      - "--host"
#      - "0.0.0.0"
  ollama:
    image: ollama/ollama:latest
    container_name: nox_ollama
    ports:
      - "192.168.86.54:11434:11434"
    volumes:
      - ./ollama_data:/root/.ollama
    restart: unless-stopped
    # Добавляем переменные окружения здесь
    environment:
      - OLLAMA_KEEP_ALIVE=-1
    deploy:
      resources:
        reservations:
          devices:
            - driver: nvidia
              count: 1
              capabilities: [gpu]


  homeassistant:
    image: homeassistant/home-assistant:stable
    container_name: nox_homeassistant
    ports:
      - "192.168.86.54:8123:8123"
    volumes:
      - ./homeassistant_config:/config
      - /etc/localtime:/etc/localtime:ro
    restart: unless-stopped